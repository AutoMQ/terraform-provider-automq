---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "automq_kafka_link Resource - automq"
subcategory: ""
description: |-
  Manage Kafka links for mirroring topics and consumer groups between AutoMQ instances and external Kafka clusters.
---

# automq_kafka_link

Manage Kafka links for mirroring topics and consumer groups between AutoMQ instances and external Kafka clusters.

## Example Usage

```terraform
resource "automq_kafka_link" "example" {
  environment_id    = var.environment_id
  instance_id       = var.instance_id
  link_id           = "example-link"
  start_offset_time = "latest"

  source_cluster = {
    endpoint          = "source-broker.example.com:9092"
    security_protocol = "SASL_SSL"
    sasl_mechanism    = "PLAIN"
    user              = "source-user"
    password          = var.source_password

    truststore_certificates = <<-EOT
    -----BEGIN CERTIFICATE-----
    MIIB...demo-truststore...IDAQAB
    -----END CERTIFICATE-----
    EOT

    keystore_certificate_chain = <<-EOT
    -----BEGIN CERTIFICATE-----
    MIIB...demo-keystore-cert...IDAQAB
    -----END CERTIFICATE-----
    EOT

    keystore_key = <<-EOT
    -----BEGIN PRIVATE KEY-----
    MIIE...demo-private-key...QAB
    -----END PRIVATE KEY-----
    EOT

    disable_endpoint_identification = false
  }
}

variable "environment_id" {
  type = string
}

variable "instance_id" {
  type = string
}

variable "source_password" {
  type      = string
  sensitive = true
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `environment_id` (String) Target AutoMQ BYOC environment identifier.
- `instance_id` (String) Kafka instance identifier that owns the link.
- `link_id` (String) Unique identifier for the Kafka link.
- `source_cluster` (Attributes) Inline configuration for the source Kafka cluster. (see [below for nested schema](#nestedatt--source_cluster))
- `start_offset_time` (String) Start offset time for mirroring. Accepted values: `latest`, `earliest`, or a Unix timestamp in milliseconds.

### Read-Only

- `created_at` (String) Creation timestamp of the link.
- `error_message` (String) Latest error message reported for the link, if any.
- `last_updated` (String) Last modification timestamp of the link.
- `status` (String) Current status of the Kafka link reported by the control plane.

<a id="nestedatt--source_cluster"></a>
### Nested Schema for `source_cluster`

Required:

- `endpoint` (String) Bootstrap servers of the source Kafka cluster (host:port list).

Optional:

- `disable_endpoint_identification` (Boolean) Disable TLS endpoint identification when required by the source cluster.
- `keystore_certificate_chain` (String, Sensitive) PEM encoded client certificate chain for mTLS connections.
- `keystore_key` (String, Sensitive) PEM encoded private key for mTLS connections.
- `password` (String, Sensitive) SASL password for the source cluster.
- `sasl_mechanism` (String) SASL mechanism when SASL is enabled (e.g. `PLAIN`, `SCRAM_SHA_512`).
- `security_protocol` (String) Security protocol to use when connecting to the source cluster (e.g. `PLAINTEXT`, `SSL`, `SASL_SSL`).
- `truststore_certificates` (String, Sensitive) PEM encoded CA certificates for TLS connections.
- `user` (String) SASL username when authentication is enabled.

## Import

Import is supported using the following syntax:

```shell
# Import format: <environment_id>@<instance_id>@<link_id>
# instance_id - Kafka instance that owns the link (for example, kf-xyz789)
# link_id     - Identifier provided when the link was created
terraform import automq_kafka_link.example env-abc123@kf-xyz789@example-link
```

After the import completes, run `terraform plan` to review any drift in optional arguments.
